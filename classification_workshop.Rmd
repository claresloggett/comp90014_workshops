---
title: "Week 11 - Classification"
output: html_document
---

This week we will buld a classifier. We start by taking some data and preparing it for our classification algorithm. We will then split the data into training and test datasets and test the model.

To get started, log into RStudio on your cloud instance (http://your-ip-address/rstudio) or if you prefer, on your own computer. See the Week 8 lab for details.

This time we'll be looking at classification, so will care more about the phenotype information for each sample than we did last week. Biobase's `pData()` function, will be useful.

Some references:

- https://en.wikibooks.org/wiki/Data_Mining_Algorithms_In_R/Classification for examples on how to use the e1071 package to classify data
- http://rocr.bioinf.mpi-sb.mpg.de/ for information on the ROCR package
- http://compbio.dfci.harvard.edu/pubs/sbtpaper/ for explanations on phenotypic varables for the breast cancer dataset

### Reminders

You can use `help()` or the `?` operator to get help on any function in R. This also works on many libraries once they are loaded.

To get help on an R operator or R keyword, you can put it in backquotes, e.g. ``help(`+`)`` or ``?`if` ``.

To see a small part of a large variable like a matrix or data frame, try `head()`.

Data frames and matrices can both be indexed with syntax like `X[rows, columns]`. The rows and columns you want can be specified in several ways, including:

- Numerical vectors specifying which rows/columns we want, e.g. `alldata[1:3,1:10]`
- Logical (TRUE/FALSE) vectors. These will return any rows/columns corresponding to TRUE values in the vector. For instance, `alldata[alldata$chromosome_name == "Y",]` returns rows where the chromosome name is Y.
- Names of columns or rows. The count for patient M00103_M, gene ENSG00000156639, can be retrieved with `alldata["ENSG00000156639","M00103_M"]`

### Data and libraries

In this lab we will again use data from the R package breastCancerNKI in Bioconductor. To install all the packages we'll need, run:
```{r eval=FALSE}
source("http://bioconductor.org/biocLite.R")
biocLite("breastCancerNKI")
biocLite("Biobase")
install.packages("gplots")
install.packages("e1071")
install.packages("ROCR")
```

Some of these may already be installed from last week. `e1071` and `ROCR` are likely to be new.

- `e1071` is a library for classification analysis, which includes a Naive Bayes classifier.
- `ROCR` is a library for visualising learning performance, with ROC curves, Precision-Recall, etc.

Once installed, use the `library()` command to load each of these packages into your R session. You should also load the `nki` data with the `data()` command.

From last week's lab, here are a few useful Biobase functions:

- `exprs(nki)` - get the expression matrix. 
- `featureNames(nki)` - get the feature (e.g. gene) names
- `experimentData(nki)` - display the experiment information
- `abstract(nki)` - display the abstract for this dataset
- `pData(nki)` - phenotype information for each sample (for instance, tumour grade)

This week, you'll need both the expression matrix and the phenotype information. You may want to save both of these to variables.

If you like, you can use `library(help=Biobase)` to see a list of all Biobase functions.

### Naive Bayes: toy data

Paste in the following toy data frame:
```{r}
outlook = c('Sunny','Sunny','Overcast','Rain','Rain','Rain','Overcast','Sunny','Sunny','Rain','Sunny','Overcast','Overcast','Rain')
temperature = c('Hot','Hot','Hot','Mild','Hot','Hot','Hot','Mild','Hot','Mild','Mild','Mild','Hot','Mild')
humidity = c('High','High','High','High','Normal','Normal','Normal','High','Normal','Normal','Normal','High','Normal','High')
wind = c('Weak','Strong','Weak','Weak','Weak','Strong','Strong','Weak','Weak','Weak','Strong','Strong','Weak','Strong')
tennis = c('No','No','Yes','Yes','Yes','No','Yes','No','Yes','Yes','Yes','Yes','Yes','No')
tennis.df = data.frame(outlook, temperature, humidity, wind, tennis)
tennis.df
```

We'll build a Naive Bayes classifier using the `naiveBayes()` function from the e1071 package. Have a look at the documentation for this function. Call this function with `tennis.df[,1:4]` as x and `tennis.df[,5]` as y. Assign the resulting model to a variable `classifier`.

Examine `classifier`. You should see a model which gives the *a priori* probabilities P(Yes) and P(No), as well as the conditional probabilities such as P(Hot|No).

You can use this model with R's `predict()` function to predict values, like
```{r eval=FALSE}
predict(classifier, tennis.df[,1:4])
```

Do the predictions match the training labels?

#### Testing

Split the data into training data and test data and assign to `testData` and `trainData`. This toy dataset is very small, so split it in half: seven rows of test data and seven of training. Build a Naive Bayes model using the training data.

Predict the classes of the training data and compare to the original labels. 

Predict the classes of the test data and compare to the real labels.

You can use the `table()` function for this, which is particularly useful when there lots of data:
```{r eval=FALSE}
predicted <- predict(classifier, testData[,1:4])
table(predicted, testData[,5])
```
This gives the True-False "confusion matrix" shown in lectures.

Try `predict()` with the parameter `type='raw'` to see the probabilities. Extract the probability of "Yes" - we'll use this as a threshold to draw some (very small) performance curves.

Try the following functions from the ROCR package on the training and test probabilities:

- `prediction()` - pass in the predicted scores (in this case, Yes probabilities) and real labels. Examine the resulting object.
- `performance()` - pass in the prediction object you just created, and choose which metrics you'd like to compare (e.g. 'sens', 'fpr'). 

Documentation, including reference manual and some introductory slides, is at http://rocr.bioinf.mpi-sb.mpg.de/ . 

You can plot the performance object to see the resulting curve.

See if you can create an ROC curve and a precision-recall curve.

### Factors in R

One basic R data type that we haven't yet covered is the **factor**. Factors represent categorical data, and are basically labelled integers. If you have a big data frame full of strings, and many are repeated (such as "Hot" and "Mild"), it's much more efficient to let R store these as integers. This also lets R compare them easily.
```{r}
humidity = c('High','High','High','High','Normal','Normal','Normal','High','Normal','Normal','Normal','High','Normal','High')
print(humidity)
as.factor(humidity)
```

Factors can be ordered or unordered. Sometimes the order doesn't matter, but sometimes there is a natural ordering, like 'Normal' and 'High'. You can force an ordering like this:
```{r}
factor(humidity, levels = c('Normal','High'))
```

When you read in tabular data from a file, R may automatically convert columns containing strings to factors. This can be something to watch out for if it's not what you want. You can explicitly control the behaviour of `read.table()` with the `stringsAsFactors` parameter.

`naiveBayes()` will want to treat any class label or non-numeric attribute as a factor, so if you have trouble, check that you are passing it factors rather than strings.

### Breast cancer dataset

Start with your expression matrix from last week ordered by variance.

#### Remove germline BRCA carriers

The genes BRCA1 and BRCA2 have a strong effect on breast cancer risk. Patients with a germline mutation in the BRCA genes will have different risks, so we'll build our expression-based classifier with patients who don't. 

Work out which sample identifiers do *not* have BRCA mutations, and select out just these samples in your expression matrix.

Hints:

- Find the BRCA mutation info:
```{r eval=FALSE}
phenotype <- pData(nki)
colnames(phenotype)
```
- Find the names of samples where the BRCA mutation value is `0`. You may want `rownames()`.
- Remember you can index your expression matrix with sample names.

#### Pick classifier geneset size

Pick the top X genes to put into your classifier (hint: use the heatmap from last week to inform your selection)

### Naive Bayes

#### Training

We'll build a Naive Bayes classifier using the `naiveBayes()` function from the e1071 package. Have a look at the documentation for this function. 

The input data to our classifier (x) will be the gene expression values, and the label we'd like to be able to predict (y) will be survival free of metastasis. This is the `e.dmfs` column in the phenotype matrix. You may want to use `is.na()` to find samples which have undefined values for this column and remove them from your data. As a hint, try to understand what's going on in the commands:
```{r eval=FALSE}
phenotype <- pData(nki)
!is.na(phenotype[,'e.dmfs'])
```
Notice the `!`, which means "not". We've used `[row,column]` notation to be clear, but could also have used shorthand such as `phenotype$e.dmfs`.

Create a vector using `as.factor()` of your class label (in this case whether they had a distant metastasis).

The `naiveBayes()` function expects the attributes, which in our case are genes, to be columns of the matrix, and samples to be rows. So you may need to take the transpose of your expression matrix with `t()`.

Watch out for sample ordering - when building the classifier, you need the samples in y to be in the same order as in X!

Split your data into a training set and test set. This means you'll need a training X and corresponding labels y, and a test X and y. You'll have to decide how many samples to use for each set. 

Use your training set to build a model with `naiveBayes()`.

#### Test

Use your model with R's `predict()` function to predict the relative probability of labels on the training data. As in the toy data section, you'll need to use the `type='raw'` parameter to the `predict()` function.

Do the same for the test data.

Plot an ROC curve of each set of predictions above using functions from the ROCR package.

#### Advanced

Try a different geneset, does performance change?

You can split your data into training, validation and test if you'd like to choose the geneset based on validation performance. You can then get real performance metrics for the resulting classifier using the test dataset.

You can also try other classifiers from the e1071 package.




